{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aa8401d73c7a19e1a43fdd6a992ea9dcb60039a2"
   },
   "source": [
    "# Overview\n",
    "Rather than trying to segment, we start off by making a model that simply tries to identify if any boat shows up in the image. \n",
    "For this model we can see roughly how it performs in the compititon by guessing the whole image (as an RLE) if any boat shows up (not a very smart startegy, but might provide some interesting results). \n",
    "\n",
    "## Beyond\n",
    "The model could also be useful as a quick way (low resolution images) to screen through lots of images to see if they are likely to have a boat and if they are then run a much more expensive full-resolution U-Net on that sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6cd9d5ad61ffe3b8858769f20a5f9493f024a56"
   },
   "source": [
    "## Model Parameters\n",
    "We might want to adjust these later (or do some hyperparameter optimizations). It is slightly easier to keep track of parallel notebooks with different parameters if they are all at the beginning in a clear (machine readable format, see Kaggling with Kaggle (https://www.kaggle.com/kmader/kaggling-with-kaggle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "trusted": true,
    "_uuid": "301a5d939c566d1487a049bb2554d09b592b18b1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLE_MODE = 'SIMPLE'\n",
    "# number of validation images to use\n",
    "VALID_IMG_COUNT = 1000\n",
    "# maximum number of training images\n",
    "MAX_TRAIN_IMAGES = 30000\n",
    "IMG_SIZE = (512,512) # [(224, 224), (384, 384), (512, 512), (640, 640)]\n",
    "BATCH_SIZE = 2 # [1, 8, 16, 24]\n",
    "DROPOUT = 0.5\n",
    "DENSE_COUNT = 128\n",
    "LEARN_RATE = 1e-3\n",
    "RGB_FLIP = 1 # should rgb be flipped when rendering images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util.montage import montage2d as montage\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "ship_dir = '/Users/janis/Documents/Python/Airbus/input'\n",
    "train_image_dir = os.path.join(ship_dir, 'train')\n",
    "test_image_dir = os.path.join(ship_dir, 'test')\n",
    "import gc; gc.enable() # memory is tight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "trusted": true,
    "_uuid": "3ca7119188fbb4c6540d9df55f5833b55435287e",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131030 masks found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104070\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>101361 1 102128 3 102896 4 103663 6 104430 9 1...</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>95225 2 95992 5 96760 7 97527 9 98294 9 99062 ...</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>74444 4 75212 4 75980 4 76748 4 77517 3 78285 ...</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>101361 1 102128 3 102896 4 103663 6 104430 9 1...</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>95225 2 95992 5 96760 7 97527 9 98294 9 99062 ...</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>74444 4 75212 4 75980 4 76748 4 77517 3 78285 ...</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = pd.read_csv(os.path.join(ship_dir,\n",
    "                                 'train_ship_segmentations.csv'))\n",
    "print(masks.shape[0], 'masks found')\n",
    "print(masks['ImageId'].value_counts().shape[0])\n",
    "masks['path'] = masks['ImageId'].map(lambda x: os.path.join(train_image_dir, x))\n",
    "masks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "40cb72e241c0c3d8bc245b4e3c663b4a835b0011"
   },
   "source": [
    "# Split into training and validation groups\n",
    "We stratify by the number of boats appearing so we have nice balances in each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "trusted": true,
    "_uuid": "871720221ac25f7f9408bfe01aeb4ccb95edbd1f",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91709 training masks\n39321 validation masks\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\n",
    "unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\n",
    "masks.drop(['ships'], axis=1, inplace=True)\n",
    "train_ids, valid_ids = train_test_split(unique_img_ids, \n",
    "                 test_size = 0.3, \n",
    "                 stratify = unique_img_ids['ships'])\n",
    "train_df = pd.merge(masks, train_ids)\n",
    "valid_df = pd.merge(masks, valid_ids)\n",
    "print(train_df.shape[0], 'training masks')\n",
    "print(valid_df.shape[0], 'validation masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c21d5bff04bf9180463969ac120379345745ed03"
   },
   "source": [
    "### Examine Number of Ship Images\n",
    "Here we examine how often ships appear and replace the ones without any ships with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "trusted": true,
    "_uuid": "fa2154d3621497e7497731e5ef6c6c72f27ad483",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>path</th>\n",
       "      <th>ships</th>\n",
       "      <th>has_ship</th>\n",
       "      <th>has_ship_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36591</th>\n",
       "      <td>6609ec824.jpg</td>\n",
       "      <td>334454 4 335216 10 335978 16 336740 23 337502 ...</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16121</th>\n",
       "      <td>2d42828e3.jpg</td>\n",
       "      <td>187914 7 188675 14 189443 14 190211 14 190979 ...</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31387</th>\n",
       "      <td>57e99ea4f.jpg</td>\n",
       "      <td>535395 1 536161 4 536928 5 537694 8 538461 10 ...</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14184</th>\n",
       "      <td>27b091c4f.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27678</th>\n",
       "      <td>4db390338.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>path</th>\n",
       "      <th>ships</th>\n",
       "      <th>has_ship</th>\n",
       "      <th>has_ship_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36591</th>\n",
       "      <td>6609ec824.jpg</td>\n",
       "      <td>334454 4 335216 10 335978 16 336740 23 337502 ...</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16121</th>\n",
       "      <td>2d42828e3.jpg</td>\n",
       "      <td>187914 7 188675 14 189443 14 190211 14 190979 ...</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31387</th>\n",
       "      <td>57e99ea4f.jpg</td>\n",
       "      <td>535395 1 536161 4 536928 5 537694 8 538461 10 ...</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14184</th>\n",
       "      <td>27b091c4f.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27678</th>\n",
       "      <td>4db390338.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Users/janis/Documents/Python/Airbus/input/tra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.sample(min(MAX_TRAIN_IMAGES, train_df.shape[0])) # limit size of training set (otherwise it takes too long)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "trusted": true,
    "_uuid": "2612fa47c7e9fdcaa7aa720c4e15fc86fd65d69a",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1cef58ec18>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x1cef4b2e80>]],\n      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['ships', 'has_ship']].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8f65e7942816fb75b687a549dc1d5cc48d00e21"
   },
   "source": [
    "# Augment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "trusted": true,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "dg_args = dict(featurewise_center = False, \n",
    "                  samplewise_center = False,\n",
    "                  rotation_range = 45, \n",
    "                  width_shift_range = 0.1, \n",
    "                  height_shift_range = 0.1, \n",
    "                  shear_range = 0.01,\n",
    "                  zoom_range = [0.9, 1.25],  \n",
    "                  brightness_range = [0.5, 1.5],\n",
    "                  horizontal_flip = True, \n",
    "                  vertical_flip = True,\n",
    "                  fill_mode = 'reflect',\n",
    "                   data_format = 'channels_last')\n",
    "valid_args = dict(fill_mode = 'reflect',\n",
    "                   data_format = 'channels_last')\n",
    "\n",
    "core_idg = ImageDataGenerator(**dg_args)\n",
    "valid_idg = ImageDataGenerator(**valid_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "trusted": true,
    "collapsed": true,
    "_uuid": "c5cc31e3117fdfa923b2acb1e6542a7007f4f955"
   },
   "outputs": [],
   "source": [
    "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n",
    "    base_dir = os.path.dirname(in_df[path_col].values[0])\n",
    "    print('## Ignore next message from keras, values are replaced anyways')\n",
    "    df_gen = img_data_gen.flow_from_directory(base_dir, \n",
    "                                     class_mode = 'sparse',\n",
    "                                    **dflow_args)\n",
    "    df_gen.filenames = in_df[path_col].values\n",
    "    df_gen.classes = np.stack(in_df[y_col].values)\n",
    "    df_gen.samples = in_df.shape[0]\n",
    "    df_gen.n = in_df.shape[0]\n",
    "    df_gen._set_index_array()\n",
    "    df_gen.directory = '' # since we have the full path\n",
    "    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n",
    "    return df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "trusted": true,
    "_uuid": "67136e1743dbbc4e07dba0d69f79231603f31d93",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Ignore next message from keras, values are replaced anyways\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\nReinserting dataframe: 30000 images\n## Ignore next message from keras, values are replaced anyways\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinserting dataframe: 39321 images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 512, 512, 3) (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "train_gen = flow_from_dataframe(core_idg, train_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'has_ship_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = BATCH_SIZE)\n",
    "\n",
    "# used a fixed dataset for evaluating the algorithm\n",
    "valid_x, valid_y = next(flow_from_dataframe(valid_idg, \n",
    "                               valid_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'has_ship_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = VALID_IMG_COUNT)) # one big batch\n",
    "print(valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "trusted": true,
    "_uuid": "6122ccb9e58bfac6fa5e11c86121e78d9e5151b1",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (2, 512, 512, 3) float32 0.0 255.0\ny (2, 1) float64 0.0 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'ships')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_x, t_y = next(train_gen)\n",
    "print('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n",
    "print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "ax1.imshow(montage_rgb((t_x-t_x.min())/(t_x.max()-t_x.min()))[:, :, ::RGB_FLIP], cmap='gray')\n",
    "ax1.set_title('images')\n",
    "ax2.plot(t_y)\n",
    "ax2.set_title('ships')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ba08494eb9736ec3556b7c879143cdcdea89febf"
   },
   "source": [
    "# Build a Model\n",
    "We build the pre-trained top model and then use a global-max-pooling (we are trying to detect any ship in the image and thus max is better suited than averaging (which would tend to favor larger ships to smaller ones). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "trusted": true,
    "_uuid": "9fb62d14ec059f7f92d82e07b35822169c77112d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0bc7c0ee177697838d22aed4de046e7542027a10"
   },
   "source": [
    "## Setup the Subsequent Layers\n",
    "Here we setup the rest of the model which we will actually be training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "trusted": true,
    "_uuid": "2687377309d3cbbab1197f4eccd2b50ab996f5a6",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nRGB_Input (InputLayer)       (None, 512, 512, 3)       0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 512, 512, 16)      448       \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 512, 512, 32)      4640      \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 256, 256, 32)      0         \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 256, 256, 32)      9248      \n_________________________________________________________________\nconv2d_16 (Conv2D)           (None, 256, 256, 32)      9248      \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 128, 128, 32)      0         \n_________________________________________________________________\nconv2d_17 (Conv2D)           (None, 128, 128, 32)      9248      \n_________________________________________________________________\nconv2d_18 (Conv2D)           (None, 128, 128, 64)      18496     \n_________________________________________________________________\nmax_pooling2d_9 (MaxPooling2 (None, 64, 64, 64)        0         \n_________________________________________________________________\nglobal_max_pooling2d_3 (Glob (None, 64)                0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 128)               8320      \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 59,777\nTrainable params: 59,777\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "img_in = layers.Input(shape=t_x.shape[1:], name=\"RGB_Input\")\n",
    "\n",
    "c1 = layers.Conv2D(16, (3,3), padding='same', activation='relu')(img_in)\n",
    "c2 = layers.Conv2D(32, (3,3), padding='same', activation='relu')(c1)\n",
    "p1 = layers.MaxPooling2D((2,2))(c2)\n",
    "\n",
    "c3 = layers.Conv2D(32, (3,3), padding='same', activation='relu')(p1)\n",
    "c4 = layers.Conv2D(32, (3,3), padding='same', activation='relu')(c3)\n",
    "p2 = layers.MaxPooling2D((2,2))(c4)\n",
    "\n",
    "c5 = layers.Conv2D(32, (3,3), padding='same', activation='relu')(p2)\n",
    "c6 = layers.Conv2D(64, (3,3), padding='same', activation='relu')(c5)\n",
    "p3 = layers.MaxPooling2D((2,2))(c6)\n",
    "\n",
    "p5 = layers.GlobalMaxPooling2D()(p3)\n",
    "dense1 = layers.Dense(128, activation='relu')(p5)\n",
    "drop = layers.Dropout(0.5)(dense1)\n",
    "out_layer = layers.Dense(1, activation='sigmoid')(drop)\n",
    "\n",
    "ship_model = models.Model(inputs = [img_in], outputs = [out_layer], name = 'full_model')\n",
    "\n",
    "ship_model.compile(optimizer = Adam(lr=LEARN_RATE), \n",
    "                   loss = 'binary_crossentropy',\n",
    "                   metrics = ['binary_accuracy'])\n",
    "\n",
    "ship_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "trusted": true,
    "_uuid": "7282d18de3aff1cee12ff89b7d511a391702814f",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights_classification.best.hdf5\".format('boat_detector')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=15) # probably needs to be more patient, but kaggle time is limited\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "5b67d808c0b8c7e28bff41e6d3858ff6f09dd626",
    "scrolled": false,
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r    1/15000 [..............................] - ETA: 16:25:17 - loss: 1.1865 - binary_accuracy: 0.5000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r    2/15000 [..............................] - ETA: 12:07:43 - loss: 0.5934 - binary_accuracy: 0.7500"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r    3/15000 [..............................] - ETA: 10:14:20 - loss: 1.3061 - binary_accuracy: 0.6667"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r    4/15000 [..............................] - ETA: 9:00:42 - loss: 5.0091 - binary_accuracy: 0.5000 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r    5/15000 [..............................] - ETA: 8:16:01 - loss: 5.7359 - binary_accuracy: 0.4000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r    6/15000 [..............................] - ETA: 7:45:17 - loss: 5.5757 - binary_accuracy: 0.4167"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r    7/15000 [..............................] - ETA: 7:23:19 - loss: 5.5355 - binary_accuracy: 0.3571"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r    8/15000 [..............................] - ETA: 7:07:56 - loss: 4.9013 - binary_accuracy: 0.3750"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r    9/15000 [..............................] - ETA: 6:55:01 - loss: 4.3568 - binary_accuracy: 0.4444"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   10/15000 [..............................] - ETA: 6:44:48 - loss: 4.3510 - binary_accuracy: 0.4500"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   11/15000 [..............................] - ETA: 6:36:25 - loss: 4.5114 - binary_accuracy: 0.4545"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   12/15000 [..............................] - ETA: 6:29:30 - loss: 4.3170 - binary_accuracy: 0.4583"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   13/15000 [..............................] - ETA: 6:25:02 - loss: 4.5726 - binary_accuracy: 0.4615"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   14/15000 [..............................] - ETA: 6:19:13 - loss: 4.2904 - binary_accuracy: 0.4643"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   15/15000 [..............................] - ETA: 6:14:27 - loss: 4.4379 - binary_accuracy: 0.4667"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   16/15000 [..............................] - ETA: 6:10:29 - loss: 4.1605 - binary_accuracy: 0.5000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   17/15000 [..............................] - ETA: 6:06:53 - loss: 3.9302 - binary_accuracy: 0.5294"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   18/15000 [..............................] - ETA: 6:04:10 - loss: 3.7798 - binary_accuracy: 0.5278"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   19/15000 [..............................] - ETA: 6:01:22 - loss: 3.5811 - binary_accuracy: 0.5526"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   20/15000 [..............................] - ETA: 5:58:42 - loss: 3.4381 - binary_accuracy: 0.5500"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   21/15000 [..............................] - ETA: 5:56:19 - loss: 3.4047 - binary_accuracy: 0.5476"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   22/15000 [..............................] - ETA: 5:54:15 - loss: 3.2673 - binary_accuracy: 0.5455"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   23/15000 [..............................] - ETA: 5:52:33 - loss: 3.2776 - binary_accuracy: 0.5217"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   24/15000 [..............................] - ETA: 5:50:55 - loss: 3.4054 - binary_accuracy: 0.5000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   25/15000 [..............................] - ETA: 5:49:37 - loss: 3.2847 - binary_accuracy: 0.5000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   26/15000 [..............................] - ETA: 5:48:08 - loss: 3.1714 - binary_accuracy: 0.5192"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   27/15000 [..............................] - ETA: 5:46:57 - loss: 3.0699 - binary_accuracy: 0.5370"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   28/15000 [..............................] - ETA: 5:48:49 - loss: 2.9851 - binary_accuracy: 0.5357"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   29/15000 [..............................] - ETA: 5:48:15 - loss: 2.9536 - binary_accuracy: 0.5345"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   30/15000 [..............................] - ETA: 5:47:15 - loss: 2.8637 - binary_accuracy: 0.5500"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   31/15000 [..............................] - ETA: 5:46:19 - loss: 2.8053 - binary_accuracy: 0.5484"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   32/15000 [..............................] - ETA: 5:45:17 - loss: 2.7563 - binary_accuracy: 0.5469"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   33/15000 [..............................] - ETA: 5:44:07 - loss: 2.7061 - binary_accuracy: 0.5455"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   34/15000 [..............................] - ETA: 5:43:36 - loss: 2.6524 - binary_accuracy: 0.5441"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   35/15000 [..............................] - ETA: 5:44:41 - loss: 2.6177 - binary_accuracy: 0.5429"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   36/15000 [..............................] - ETA: 5:45:15 - loss: 2.5525 - binary_accuracy: 0.5556"
     ]
    }
   ],
   "source": [
    "train_gen.batch_size = BATCH_SIZE\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "ship_model.fit_generator(train_gen, \n",
    "                      validation_data = (valid_x, valid_y), \n",
    "                      epochs = 10,\n",
    "                      callbacks = callbacks_list,\n",
    "                      workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "collapsed": true,
    "_uuid": "a168c8b1af446b800f6129104906003ededd61c4"
   },
   "outputs": [],
   "source": [
    "ship_model.load_weights(weight_path)\n",
    "ship_model.save('full_ship_classification_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "17edb177402ae51651692511827a7e9d60646533"
   },
   "source": [
    "# Run the test data\nWe use the sample_submission file as the basis for loading and running the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "trusted": true,
    "_uuid": "4911811f267f9f3397a58902da9e75c6f261ad40",
    "collapsed": true
   },
   "source": [
    "test_paths = os.listdir(test_image_dir)\nprint(len(test_paths), 'test images found')\nsubmission_df = pd.read_csv('../input/sample_submission.csv')\nsubmission_df['path'] = submission_df['ImageId'].map(lambda x: os.path.join(test_image_dir, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5b3eea954bd883d598c6ac80167dfd4353b0f558"
   },
   "source": [
    "# Setup Test Data Generator\nWe use the same generator as before to read and preprocess images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "trusted": true,
    "_uuid": "f75595679ba8606fd1ac15645b8612e117db0b30",
    "collapsed": true
   },
   "source": [
    "test_gen = flow_from_dataframe(valid_idg, \n                               submission_df, \n                             path_col = 'path',\n                            y_col = 'ImageId', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = BATCH_SIZE, \n                              shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "trusted": true,
    "_uuid": "73ef7b3b2a74bf64968c79b4005075d4f0e23143",
    "collapsed": true
   },
   "source": [
    "fig, m_axs = plt.subplots(3, 2, figsize = (20, 30))\nfor (ax1, ax2), (t_x, c_img_names) in zip(m_axs, test_gen):\n    t_y = ship_model.predict(t_x)\n    t_stack = ((t_x-t_x.min())/(t_x.max()-t_x.min()))[:, :, :, ::RGB_FLIP]\n    ax1.imshow(montage_rgb(t_stack))\n    ax1.set_title('images')\n    alpha_stack = np.tile(np.expand_dims(np.expand_dims(t_y, -1), -1), [1, t_stack.shape[1], t_stack.shape[2], 1])\n    rgba_stack = np.concatenate([t_stack, alpha_stack], -1)\n    ax2.imshow(montage_rgb(rgba_stack))\n    ax2.set_title('ships')\nfig.savefig('test_predictions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "22f5f7e53cb82ff54bfb0e4ee818315d05c1e1af"
   },
   "source": [
    "# Prepare Submission\nProcess all images (batchwise) and keep the score at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "trusted": true,
    "_uuid": "b103e0ce6ccae69dbf82a55067dc693efaeadf8f",
    "collapsed": true
   },
   "source": [
    "BATCH_SIZE = BATCH_SIZE*2 # we can use larger batches for inference\ntest_gen = flow_from_dataframe(valid_idg, \n                               submission_df, \n                             path_col = 'path',\n                            y_col = 'ImageId', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = BATCH_SIZE, \n                              shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "trusted": true,
    "_uuid": "0a38d343b2654f87934a88524ebc14a5759e07cb",
    "collapsed": true
   },
   "source": [
    "from tqdm import tqdm_notebook\nall_scores = dict()\nfor _, (t_x, t_names) in zip(tqdm_notebook(range(test_gen.n//BATCH_SIZE+1)),\n                            test_gen):\n    t_y = ship_model.predict(t_x)[:, 0]\n    for c_id, c_score in zip(t_names, t_y):\n        all_scores[c_id] = c_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4a942dbb4a939d73526dbb35745402b35785fdf4"
   },
   "source": [
    "# Show the Scores\nHere we see the scores and we have to decide about a cut-off for counting an image as ship or not. We can be lazy and pick 0.5 but some more rigorous cross-validation would definitely improve this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "trusted": true,
    "_uuid": "41ab9326407f59c983f3991ff736da8dd822605c",
    "collapsed": true
   },
   "source": [
    "submission_df['score'] = submission_df['ImageId'].map(lambda x: all_scores.get(x, 0))\nsubmission_df['score'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fae5322806f03112d8110755ca48a3bdb05eeded"
   },
   "source": [
    "# Make the RLE data if there is a ship\nHere we make the RLE data for a positive image (assume every pixel is ship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "trusted": true,
    "_uuid": "80acd5482d2a6117648a842b2f0da380bced79a5",
    "collapsed": true
   },
   "source": [
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n# empty image\nzp_dim = 10\nout_img = np.ones((768-2*zp_dim, 768-2*zp_dim), dtype=bool)\nout_img = np.pad(out_img, ((zp_dim, zp_dim),), mode='constant', constant_values=0)\nplt.matshow(out_img)\nprint(out_img.shape)\npos_ship_str = rle_encode(out_img)\nprint(pos_ship_str[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "trusted": true,
    "_uuid": "580506b6e934b9a9a362deaf6b88e5d71c770405",
    "collapsed": true
   },
   "source": [
    "# add the whole image if it is above the threshold\nsubmission_df['EncodedPixels'] = submission_df['score'].map(lambda x: pos_ship_str if x>0.5 else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "trusted": true,
    "_uuid": "b534a825f5a1997a935aa3e3f338da657024bc19",
    "collapsed": true
   },
   "source": [
    "out_df = submission_df[['ImageId', 'EncodedPixels']]\nout_df.to_csv('submission.csv', index=False)\nout_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "collapsed": true,
    "_uuid": "07dd065b26b4018ea76bd7d90ee9639a2b2c7480"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
