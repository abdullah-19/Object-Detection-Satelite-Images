{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Overview\n",
    "For the submission we first run determine whether a picture contains a boat. This is done by using the classification model that has been trained. \n",
    "For the images that contain a boat we use the trained instance segmentation U-net to detect boats in the images and classify each pixel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classification model\n",
    "Predict whether test images contain a boat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "clf_model = load_model(\"models/ship_classification_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001b1832.jpg</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00052ed46.jpg</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000532683.jpg</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001b1832.jpg</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00052ed46.jpg</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000532683.jpg</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import the sample submission csv\n",
    "sample_submission = pd.read_csv('input/sample_submission.csv')\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total there are 88486 test images\n"
     ]
    }
   ],
   "source": [
    "pictures = sample_submission.ImageId.unique()\n",
    "print('In total there are {} test images'.format(len(pictures)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001b1832.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00052ed46.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000532683.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001b1832.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00052ed46.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000532683.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "clf_submission = pd.DataFrame(pictures, columns=['ImageId'])\n",
    "clf_submission = clf_submission.assign(Prediction=pd.Series([np.NaN for _ in range(len(pictures))]).values)\n",
    "\n",
    "clf_submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction for all images\n",
    "for picture in tqdm_notebook(pictures[:100]):\n",
    "    img_path = os.path.join('input/test', picture)\n",
    "    img = mpimg.imread(img_path)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    pred = clf_model.predict(img)[0][0]\n",
    "    if pred < 0.5:\n",
    "        # add 0 to image\n",
    "        clf_submission.loc[clf_submission.index[clf_submission.ImageId == picture], 'Prediction'] = 0\n",
    "    else:\n",
    "        # add 1 to image\n",
    "        clf_submission.loc[clf_submission.index[clf_submission.ImageId == picture], 'Prediction'] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb2dc1a860>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_submission.Prediction.hist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We determined the images that do not contain boats. Now we can have a look at the images that, according to our classification model, do contain boats. For these images we use the previously trained object detection model to classify each pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001b1832.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00052ed46.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000532683.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001b1832.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00052ed46.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000532683.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_submission['Prediction'] = clf_submission['Prediction'].map(lambda x: np.NaN if x == 0 else x)\n",
    "is_boat = clf_submission.Prediction.notnull()\n",
    "clf_submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = K.sum(y_true, axis=[1, 2, 3]) + K.sum(y_pred, axis=[1, 2, 3])\n",
    "    return K.mean((2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "\n",
    "def dice_p_bce(in_gt, in_pred):\n",
    "    return 1e-3 * binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n",
    "\n",
    "def true_positive_rate(y_true, y_pred):\n",
    "    return K.sum(K.flatten(y_true) * K.flatten(K.round(y_pred))) / K.sum(y_true)\n",
    "\n",
    "def IoU(y_true, y_pred, eps=1e-6):\n",
    "    if np.max(y_true) == 0.0:\n",
    "        return IoU(1 - y_true, 1 - y_pred)  ## empty image; calc IoU of zeros\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = K.sum(y_true, axis=[1, 2, 3]) + K.sum(y_pred, axis=[1, 2, 3]) - intersection\n",
    "    return -K.mean((intersection + eps) / (union + eps), axis=0)\n",
    "\n",
    "\n",
    "seg_model = load_model(\"models/segmentation_model_final_v1.h5\",\n",
    "                   custom_objects={'dice_p_bce': dice_p_bce, 'dice_coef': dice_coef,\n",
    "\n",
    "                                   'true_positive_rate': true_positive_rate,\n",
    "                                   'IoU': IoU})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    img_path = os.path.join('input/test', img)\n",
    "    img = mpimg.imread(img_path)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    pred = seg_model.predict(img)[0]\n",
    "    pred = binary_opening(pred > 0.99, np.expand_dims(disk(2), -1))\n",
    "    pred = remove_small_objects(pred, connectivity=2)\n",
    "    return pred, img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0]\n  [0]\n  [0]\n  ...\n  [0]\n  [0]\n  [0]]\n\n [[0]\n  [0]\n  [0]\n  ...\n  [0]\n  [0]\n  [0]]\n\n [[0]\n  [0]\n  [0]\n  ...\n  [0]\n  [0]\n  [0]]\n\n ...\n\n [[0]\n  [0]\n  [0]\n  ...\n  [0]\n  [0]\n  [0]]\n\n [[0]\n  [0]\n  [0]\n  ...\n  [0]\n  [0]\n  [0]]\n\n [[0]\n  [0]\n  [0]\n  ...\n  [0]\n  [0]\n  [0]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0]\n  [0]\n  [0]\n  ...\n  [0]\n  [0]\n  [0]]\n\n [[0]\n  [0]\n  [0]\n  ...\n  [0]\n  [0]\n  [0]]\n\n [[0]\n  [0]\n  [0]\n  ...\n  [0]\n  [0]\n  [0]]\n\n ...\n\n [[0]\n  [0]\n  [0]\n  ...\n  [0]\n  [0]\n  [0]]\n\n [[0]\n  [0]\n  [0]\n  ...\n  [0]\n  [0]\n  [0]]\n\n [[0]\n  [0]\n  [0]\n  ...\n  [0]\n  [0]\n  [0]]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-4bac16e31c8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mout_pred_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpicture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclf_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageId\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mis_boat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpicture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-92-c419ac03866f>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_opening\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_small_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnectivity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1165\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.morphology import binary_opening, disk, label, remove_small_objects\n",
    "\n",
    "out_pred_rows = list()\n",
    "for picture in clf_submission.ImageId[is_boat]:\n",
    "    pred, img = predict(picture)\n",
    "    labels = label(pred)\n",
    "    print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
